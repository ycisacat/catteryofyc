#coding=utf-8
import re,chardet,urllib

class crawlNews:
    def getUrl(self):
        url="http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&" \
            "ch=01&k=&offset_page=0&offset_num=0&num=5000&asc=&page=3&r=0.4589775952558407"
        text=urllib.urlopen(url).read()
        c=chardet.detect(text) #查询网站的编码方式
        code=c['encoding'] #直接print code:{'confidence': 0.99, 'encoding': 'GB2312'}
        # print code  #只打印encoding,字典
        text=str(text).decode(code,'ignore').encode('utf-8') #ignore忽略异常编码
        # print "text",text #5000条网页连接

        #抓取本页连接
        #link=r'<li>.*?</a>'
        pattern1=re.compile('http.*?shtml')
        l=re.findall(pattern1,text)
        return l

#获取新闻标题作为txt标题#
    def getTitle(self,psg):
        title=r'<title>(.*)</title>'
        pattern2=re.compile(title)
        mytitle=re.search(pattern2,psg)
        if mytitle:
            return mytitle.group(1).strip()
        else:
            return None

#写txt标题#
    def setTitle(self,mytitle):
        self.defaultTitle ="News"
        if mytitle is not None:
            mytitle=str(mytitle)
            print mytitle
            xiegang=re.compile('/')
            mytitle=re.sub(xiegang,'', mytitle)
            self.file=open(mytitle +'.txt','w+')
        else:
            self.file=open(self.defaultTitle +'.txt','w+')
        return mytitle

#去除正文多余内容
    def remove(self,x):
        removeA=re.compile('<a.*?</a>')
        removeExtra=re.compile('<.*?>|</.*?>')
        x=re.sub(removeA," ",x)
        x=re.sub(removeExtra," ",x)
        return x.strip()

#获取新闻内容并写入txt
    def getData(self,psg):
        data=r'<p>(.*?)</p>'
        pattern3=re.compile(data,re.S)
        mydata=re.findall(pattern3,psg) #文字,理论上时未经去除标签的正文
        contents=[]  #这里开始去除工作
        for a in mydata:
            content=self.remove(a)+"\n"
            contents.append(content)
        for j in contents:
            i=1
            print "正在输出第",i,"篇新闻"
            i+=1
            self.file.write(j)
        self.file.close()
        return psg

spider = crawlNews()
l=spider.getUrl()
print len(l),l
for i in l:   #解码
    print i
    web=urllib.urlopen(i).read()
    code2=chardet.detect(web) #查询网站的编码方式
    cw=code2['encoding'] #直接print code:{'confidence': 0.99, 'encoding': 'GB2312'}
    web=str(web).decode(cw,'ignore').encode('utf-8')
    pageCode = web #正式开工段
    title = spider.getTitle(pageCode)
    txtTitle=spider.setTitle(title)
    passage=spider.getData(pageCode)

